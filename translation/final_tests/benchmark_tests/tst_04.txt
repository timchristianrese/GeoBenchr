# ===== postgis ============================================================
SELECT k.name, COUNT(DISTINCT f.flightid) AS flight_count
FROM counties k
INNER JOIN flight_points f ON (ST_Intersects(f.geom, k.geom))
WHERE (k.name = 'Krs Hochsauerlandkreis')
GROUP BY k.name;

# ===== sedona ============================================================
# --- bootstrap Spark + Sedona ----------------------------------------------
from pyspark.sql import SparkSession
import pyspark

# déterminer automatiquement la bonne paire Spark / Scala
spark_mm  = '.'.join(pyspark.__version__.split('.')[:2])        # "3.4", "3.5", …
scala_ver = '2.13' if float(spark_mm) >= 3.5 else '2.12'

sedona_version = "1.7.2"                                        # dernière sur PyPI
sedona_pkg   = f"org.apache.sedona:sedona-spark-{spark_mm}_{scala_ver}:{sedona_version}"
geotools_pkg = f"org.datasyslab:geotools-wrapper:{sedona_version}-28.5"

try:
    spark                              # existe déjà si lancé via spark-submit
except NameError:
    spark = (
        SparkSession.builder
        .appName("sedona_auto")
        .config("spark.jars.packages", f"{sedona_pkg},{geotools_pkg}")
        .config("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
        .config("spark.kryo.registrator",
                "org.apache.sedona.core.serde.SedonaKryoRegistrator")
        .getOrCreate()
    )

from sedona.register import SedonaRegistrator
SedonaRegistrator.registerAll(spark)
# Optimisations performance
spark.sparkContext.setLogLevel("ERROR")          # moins de bruit
spark.conf.set("spark.sql.shuffle.partitions", "256")  # adapte selon tes CPU (128 / 256 / 512)
spark.conf.set("spark.sql.adaptive.enabled", "true")

# Index spatial global (évite la construction 'on the fly' lente)
spark.conf.set("sedona.global.index", "true")
spark.conf.set("sedona.global.indextype", "quadtree")  # ou "rtree"
# ---------------------------------------------------------------------------
# Auto‑generated Sedona RDD query — DO NOT EDIT BY HAND

df = None  # Placeholder to avoid NameError if joins exist
reader = (spark.read
    .option("delimiter", ";")
    .option("header", "true")
    .option("encoding", "UTF-8")
    .option("quote", "\"")
    .option("escape", "\\")
    .option("inferSchema", "false")
    .csv("counties-wkt.csv") )
df_tmp = reader
from pyspark.sql import functions as F
from sedona.sql.types import GeometryType
df_tmp = df_tmp.withColumn("geom", F.expr("ST_GeomFromWKT(polygon)").cast(GeometryType()))
df = df_tmp
df.createOrReplaceTempView("k")
df.createOrReplaceTempView("counties")
reader = (spark.read
    .option("delimiter", ";")
    .option("header", "false")
    .option("encoding", "UTF-8")
    .option("quote", "\"")
    .option("escape", "\\")
    .option("inferSchema", "false")
    .csv("point_NRW_HIGH_0123.csv") )

# Limiter le nombre de lignes pour le test
reader_limited = reader.limit(200000)   # ajuste le nombre

df_tmp = reader_limited.toDF("flightid", "airplanetype", "origin", "destination", "wkt", "timestamp", "altitude")
from pyspark.sql import functions as F
df_tmp = df_tmp.withColumn("altitude", F.col("altitude").cast("double"))
from sedona.sql.types import GeometryType
df_tmp = df_tmp.withColumn("geom", F.expr("ST_GeomFromWKT(wkt)").cast(GeometryType()))

from pyspark.sql import functions as F
df_tmp = df_tmp.withColumn("altitude", F.col("altitude").cast("double"))
from pyspark.sql import functions as F
from sedona.sql.types import GeometryType
df_tmp = df_tmp.withColumn("geom", F.expr("ST_GeomFromWKT(wkt)").cast(GeometryType()))
df_f = df_tmp
df_f.createOrReplaceTempView("f")
df_f.createOrReplaceTempView("flight_points")
df = spark.sql("""
    SELECT k.name AS `k.name`, f.flightid AS `f.flightid`
    FROM k
    JOIN f
    ON (ST_Intersects(f.geom, k.geom))
    WHERE ((k.name = 'Krs Hochsauerlandkreis'))
""")
from pyspark.sql import functions as F
df = df.filter("`k.name` IS NOT NULL AND `k.name` <> ''")
df = df.groupBy(F.col("`k.name`")).agg(F.countDistinct(F.col("`f.flightid`")).alias("flight_count"))
result = df

# Final result variable is: result
result.show()

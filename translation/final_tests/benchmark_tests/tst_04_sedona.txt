# --- bootstrap Spark + Sedona ----------------------------------------------
from pyspark.sql import SparkSession
import pyspark

# déterminer automatiquement la bonne paire Spark / Scala
spark_mm  = '.'.join(pyspark.__version__.split('.')[:2])        # "3.4", "3.5", …
scala_ver = '2.13' if float(spark_mm) >= 3.5 else '2.12'

sedona_version = "1.7.2"                                        # dernière sur PyPI
sedona_pkg   = f"org.apache.sedona:sedona-spark-{spark_mm}_{scala_ver}:{sedona_version}"
geotools_pkg = f"org.datasyslab:geotools-wrapper:{sedona_version}-28.5"

try:
    spark                              # existe déjà si lancé via spark-submit
except NameError:
    spark = (
        SparkSession.builder
        .appName("sedona_auto")
        .config("spark.jars.packages", f"{sedona_pkg},{geotools_pkg}")
        .config("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
        .config("spark.kryo.registrator",
                "org.apache.sedona.core.serde.SedonaKryoRegistrator")
        .getOrCreate()
    )

from sedona.register import SedonaRegistrator
SedonaRegistrator.registerAll(spark)
# ---------------------------------------------------------------------------
# Auto-generated Sedona query — DO NOT EDIT BY HAND

df = None  # Placeholder to avoid NameError if joins exist
reader = (spark.read
    .option("delimiter", ";")
    .option("header", "true")
    .option("encoding", "UTF-8")
    .option("quote", "\"")
    .option("escape", "\\")
    .option("inferSchema", "false")
    .csv("counties-wkt.csv") )
df_tmp = reader
from pyspark.sql import functions as F
from sedona.sql.types import GeometryType
df_tmp = df_tmp.withColumn("geom", F.expr("ST_GeomFromWKT(polygon)").cast(GeometryType()))
df = df_tmp
df.createOrReplaceTempView("k")
df.createOrReplaceTempView("counties")
reader = (spark.read
    .option("delimiter", ";")
    .option("header", "false")
    .option("encoding", "UTF-8")
    .option("quote", "\"")
    .option("escape", "\\")
    .option("inferSchema", "false")
    .csv("point_NRW_HIGH_0123.csv") )
df_tmp = reader.toDF("flightid", "airplanetype", "origin", "destination", "wkt", "timestamp", "altitude")
from pyspark.sql import functions as F
df_tmp = df_tmp.withColumn("altitude", F.col("altitude").cast("double"))
from pyspark.sql import functions as F
from sedona.sql.types import GeometryType
df_tmp = df_tmp.withColumn("geom", F.expr("ST_GeomFromWKT(wkt)").cast(GeometryType()))
df_f = df_tmp
df_f.createOrReplaceTempView("f")
df_f.createOrReplaceTempView("flight_points")
df = spark.sql("""
    SELECT k.name AS `k.name`, f.flightid AS `f.flightid`
    FROM k
    JOIN f
    ON (ST_Intersects(f.geom, k.geom))
    WHERE (k.name = 'Krs Hochsauerlandkreis')
""")
from pyspark.sql import functions as F
df = df.filter("`k.name` IS NOT NULL AND `k.name` <> ''")
df = df.groupBy(F.col("`k.name`")).agg(F.countDistinct(F.col("`f.flightid`")).alias("flight_count"))
result = df

# Final result variable is: result
result.show()
